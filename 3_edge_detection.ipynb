{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Edge and line detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataDir = \"Images_03a\"  # Change this, according to your images' directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "img = cv2.imread(\n",
    "    os.path.join(dataDir, \"corridor_01.jpg\")\n",
    ")  # Change this, according to your image's path\n",
    "\n",
    "# Convert to grayscale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sobel Filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting edges using the [Sobel Filter](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first derivatives of the image in x and y\n",
    "sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "# Show the images\n",
    "cv2.imshow(\"Sobel X\", sobel_x)\n",
    "cv2.imshow(\"Sobel Y\", sobel_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1: Calculate the gradient by combining the X and Y axes and show the gradient image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_xy = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=5)\n",
    "\n",
    "# Show the images\n",
    "cv2.imshow(\"Sobel XY\", sobel_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2: Threshold the gradient image using a [trackbar](https://docs.opencv.org/4.x/da/d6a/tutorial_trackbar.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(value, edges_image):\n",
    "    _, thresholded_image = cv2.threshold(edges_image, value, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"Edges\", thresholded_image)\n",
    "\n",
    "\n",
    "edges_image = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=5)\n",
    "\n",
    "cv2.imshow(\"Edges\", edges_image)\n",
    "cv2.createTrackbar(\n",
    "    \"Threshold\", \"Edges\", 0, 255, lambda value: apply_threshold(value, edges_image)\n",
    ")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3: Test the effect of applying Gaussian blur filters of different sizes before applying Sobel filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3, 5, 9, 15]\n",
    "\n",
    "for i in kernel_sizes:\n",
    "    img_blurred = cv2.GaussianBlur(img, (i, i), 0)\n",
    "    edges_blurred = cv2.Sobel(img_blurred, cv2.CV_64F, 1, 1, ksize=5)\n",
    "    cv2.imshow(f\"Edges with Blurred Image {i}x{i}\", edges_blurred)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.4: Experiment with different kernel sizes in the sobel filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3, 5, 9, 15]\n",
    "\n",
    "for i in kernel_sizes:\n",
    "    edges = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=i)\n",
    "    cv2.imshow(f\"Edges with Kernel Size {i}x{i}\", edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Laplacian of Gaussians (LoG) and Difference of Gaussians (DoG)\n",
    "\n",
    "Edge detection using Laplacian of Gaussians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "img = cv2.imread(\n",
    "    os.path.join(dataDir, \"corridor_01.jpg\")\n",
    ")  # Change this, according to your image's path\n",
    "\n",
    "# Convert to grayscale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Laplacian\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow(\"LoG\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1: Verify the effects of using Gaussian Blur before applying the laplacian filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blurred = cv2.GaussianBlur(img, (9, 9), 0)\n",
    "laplacian_blurred = cv2.Laplacian(img_blurred, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow(\"LoG with Blurred Image\", laplacian_blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2: Implement edge detection through Difference of Gaussians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_1 = cv2.GaussianBlur(img, (3, 3), 0, 0)\n",
    "gaussian_2 = cv2.GaussianBlur(img, (5, 5), 0, 0)\n",
    "\n",
    "dog = gaussian_2 - gaussian_1\n",
    "\n",
    "cv2.imshow(\"DoG\", dog)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Canny Edge Filter\n",
    "\n",
    "Detect edges using the [Canny Filter](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Canny Filter\n",
    "img_canny = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow(\"Image\", img_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1: Implement a track bar to alter the low and high threshold values of the Canny filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m     img_canny \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCanny(\n\u001b[1;32m      3\u001b[0m         img,\n\u001b[1;32m      4\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin Threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax Threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_canny)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mnamedWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mWINDOW_AUTOSIZE)\n\u001b[1;32m     12\u001b[0m img_canny \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCanny(img, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_canny)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def apply_threshold(img):\n",
    "    img_canny = cv2.Canny(\n",
    "        img,\n",
    "        cv2.getTrackbarPos(\"Min Threshold\", \"Canny Thresholds\"),\n",
    "        cv2.getTrackbarPos(\"Max Threshold\", \"Canny Thresholds\"),\n",
    "    )\n",
    "    cv2.imshow(\"Canny Thresholds\", img_canny)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Canny Thresholds\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "img_canny = cv2.Canny(img, 100, 200)\n",
    "cv2.imshow(\"Canny Thresholds\", img_canny)\n",
    "\n",
    "cv2.createTrackbar(\n",
    "    \"Min Threshold\", \"Canny Thresholds\", 100, 255, lambda _: apply_threshold(img)\n",
    ")\n",
    "\n",
    "cv2.createTrackbar(\n",
    "    \"Max Threshold\", \"Canny Thresholds\", 200, 255, lambda _: apply_threshold(img)\n",
    ")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2: Compare the results of applying the following two filters to the same image:\n",
    "\n",
    "- Sobel filter, with threshold t, after smoothing the image with a Gaussian blur filter with size s;\n",
    "- Canny filter, with \"low threshold\" = \"high threshold\" = t and \"aperture\" = s, using the same t and s values. Try also with a \"low threshold\" different from the \"high threshold\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 150\n",
    "s = 5\n",
    "\n",
    "img_blurred = cv2.GaussianBlur(img, (s, s), 0)\n",
    "img_sobel = cv2.Sobel(img_blurred, cv2.CV_64F, 1, 1, ksize=s)\n",
    "img_thresholded = cv2.threshold(img_sobel, t, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "cv2.imshow(\"Thresholded\", img_thresholded)\n",
    "\n",
    "img_canny = cv2.Canny(img, t, t, apertureSize=s)\n",
    "cv2.imshow(\"Canny\", img_canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Hough Line Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of [Standard Hough Lines Transform](https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img2 = cv2.imread(os.path.join(dataDir, \"chessboard_02.jpg\"))\n",
    "\n",
    "# Convert to grayscale\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Image\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Detect the edges of the input image using a Canny Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Canny filter\n",
    "img2_canny = cv2.Canny(img2, 50, 200)\n",
    "\n",
    "# Create BGR copy of image\n",
    "img2_copy = cv2.cvtColor(img2_canny, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Canny\", img2_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Apply Hough Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_votes = 60\n",
    "\n",
    "lines = cv2.HoughLines(img2_canny, 1, np.pi / 180, num_votes, None, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Draw the lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "        # Draw the line\n",
    "        cv2.line(img2_copy, pt1, pt2, (255, 0, 0), 3)\n",
    "\n",
    "cv2.imshow(\"Canny\", img2_canny)\n",
    "cv2.imshow(\"Image\", img2_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
