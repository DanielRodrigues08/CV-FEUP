{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "vFgSsbJQUB6m"
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torchvision import transforms\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "import torch.nn.functional as F\n",
                "import os\n",
                "import json\n",
                "from torchsummary import summary\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "base_folder = \"/content/drive/Shareddrives/VC/\"\n",
                "models_folder = base_folder + \"models/\"\n",
                "plot_data = base_folder + \"plot_data/\"\n",
                "image_paths_file = base_folder + \"image_paths.txt\"\n",
                "\n",
                "if not os.path.exists(models_folder):\n",
                "    os.makedirs(models_folder)\n",
                "\n",
                "if not os.path.exists(plot_data):\n",
                "    os.makedirs(plot_data)\n"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "HAPHR4LDf4A5",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1715852925141,
                    "user_tz": -60,
                    "elapsed": 30553,
                    "user": {
                        "displayName": "Andr\u00e9 Filipe Garcez Moreira de Sousa",
                        "userId": "09231004892304125355"
                    }
                },
                "outputId": "3b3432c4-11b2-4eba-d79e-b9a00a855201"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!cp"
            ],
            "metadata": {
                "id": "p7OSmvE7Iivk"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Helper Functions:**"
            ],
            "metadata": {
                "id": "lVOjInw5hOOh"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def draw_bar_plot(labels):\n",
                "    unique_labels = list(set(labels))\n",
                "    counts = [labels.count(label) for label in unique_labels]\n",
                "\n",
                "    plt.bar(range(len(unique_labels)), counts, color='skyblue')\n",
                "    plt.xlabel('Label')\n",
                "    plt.ylabel('Frequency')\n",
                "    plt.title('Bar Plot of Labels')\n",
                "    plt.xticks(range(len(unique_labels)), unique_labels)  # Set x-axis labels\n",
                "    plt.show()"
            ],
            "metadata": {
                "id": "zbEU2hdvhSTR"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def list_files(folder_path):\n",
                "    return [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]"
            ],
            "metadata": {
                "id": "sYMAN5sQhWAG"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def plotTrainingHistory(train_history, val_history):\n",
                "    plt.subplot(2, 1, 1)\n",
                "    plt.title('Cross Entropy Loss')\n",
                "    plt.plot(train_history['loss'], label='train')\n",
                "    plt.plot(val_history['loss'], label='val')\n",
                "    plt.legend(loc='best')\n",
                "\n",
                "    plt.subplot(2, 1, 2)\n",
                "    plt.title('Classification Accuracy')\n",
                "    plt.plot(train_history['accuracy'], label='train')\n",
                "    plt.plot(val_history['accuracy'], label='val')\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.legend(loc='best')\n",
                "    plt.show()"
            ],
            "metadata": {
                "id": "8uRbDEA37lXd"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def save_dict_to_file(data, filename):\n",
                "  with open(filename, 'w') as file:\n",
                "    json.dump(data, file)\n",
                "\n",
                "def get_saved_dict(filename):\n",
                "  with open(filename, 'r') as file:\n",
                "      data = json.load(file)\n",
                "  return data\n"
            ],
            "metadata": {
                "id": "SuOCFaKe-DNW"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def get_files():\n",
                "  image_paths = []\n",
                "  if os.path.exists(image_paths_file):\n",
                "    with open(image_paths_file, \"r\") as file:\n",
                "      lines = file.readlines()\n",
                "      # Strip newline characters and append to list\n",
                "      image_paths = [line.strip() for line in lines]\n",
                "  else:\n",
                "    image_paths.extend(list_files(f\"{base_folder}/drive_dataset/\"))\n",
                "    for chunk_id in range(1, 7+1):\n",
                "      print(chunk_id)\n",
                "      image_paths.extend(list_files(f\"{base_folder}/generated_dataset/chunk_{chunk_id}\"))\n",
                "    with open(image_paths_file, \"w\") as file:\n",
                "      file.writelines(path + \"\\n\" for path in image_paths)\n",
                "  return image_paths\n"
            ],
            "metadata": {
                "id": "RV9ihbyqkES9"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Dataset:**"
            ],
            "metadata": {
                "id": "SMnoM0fU_tpW"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class LegoDataset(Dataset):\n",
                "    def __init__(self, image_paths, labels, transform=None):\n",
                "        self.image_paths = image_paths\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        img_path = self.image_paths[idx]\n",
                "        image = Image.open(img_path).convert(\"RGB\")\n",
                "        label = self.labels[idx]\n",
                "\n",
                "        if self.transform:\n",
                "            image = self.transform(image)\n",
                "\n",
                "        return image, label"
            ],
            "metadata": {
                "id": "rsGtHXtcUFCL"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "batch_size = 64\n",
                "num_workers = 4\n",
                "image_size = (520, 390)\n",
                "train_size = 0.7\n",
                "validation_size = 0.2\n",
                "test_size = 0.1"
            ],
            "metadata": {
                "id": "iGF-vxYaizWc"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "image_paths = get_files()\n",
                "\n",
                "image_paths = list(filter(lambda x: \"(\" not in x, image_paths))\n",
                "labels = list(map(lambda x: int(x[x.rfind('_')+1:x.rfind('.')]), image_paths))\n",
                "\n",
                "draw_bar_plot(labels)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 472
                },
                "id": "WN_Rr0brdC3C",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1715852926397,
                    "user_tz": -60,
                    "elapsed": 1270,
                    "user": {
                        "displayName": "Andr\u00e9 Filipe Garcez Moreira de Sousa",
                        "userId": "09231004892304125355"
                    }
                },
                "outputId": "db03ba00-fae4-417e-da12-3c637964aa50"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "image_paths = np.asarray(image_paths)\n",
                "labels = np.asarray(labels)\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(image_size),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Lambda(lambda x: x + 0.1 * torch.randn_like(x) if torch.rand(1) < 0.5 else x),  # Add Gaussian noise to the image\n",
                "    transforms.RandomVerticalFlip(),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Randomly split data into train (0), validation (1) and test (2) sets\n",
                "split = np.random.choice([0, 1, 2], len(image_paths), p=[train_size, validation_size, test_size])\n",
                "\n",
                "train_indexes = np.where(split == 0)[0]\n",
                "valid_indexes = np.where(split == 1)[0]\n",
                "test_indexes = np.where(split == 2)[0]\n",
                "\n",
                "train_dataset = LegoDataset(image_paths[train_indexes], labels[train_indexes], transform=transform)\n",
                "valid_dataset = LegoDataset(image_paths[valid_indexes], labels[valid_indexes], transform=transform)\n",
                "test_dataset = LegoDataset(image_paths[test_indexes], labels[test_indexes], transform=transform)\n",
                "\n",
                "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
                "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
                "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0, shuffle=False)"
            ],
            "metadata": {
                "id": "-PUfmlje_xbo",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "outputId": "b690177f-c86d-4de4-c215-8be76e942492",
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1715852926398,
                    "user_tz": -60,
                    "elapsed": 63,
                    "user": {
                        "displayName": "Andr\u00e9 Filipe Garcez Moreira de Sousa",
                        "userId": "09231004892304125355"
                    }
                }
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Model:**"
            ],
            "metadata": {
                "id": "CMvbYRDq-2ub"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class CustomCNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(CustomCNN, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
                "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
                "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
                "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n",
                "        self.conv5 = nn.Conv2d(256, 64, kernel_size=1)\n",
                "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "        self.fc1 = nn.Linear(64*15*11, 1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(torch.relu(self.conv1(x)))\n",
                "        x = self.pool(torch.relu(self.conv2(x)))\n",
                "        x = self.pool(torch.relu(self.conv3(x)))\n",
                "        x = self.pool(torch.relu(self.conv4(x)))\n",
                "        x = self.pool(torch.relu(self.conv5(x)))\n",
                "        x = torch.flatten(x, start_dim=1)\n",
                "        x = self.fc1(x)\n",
                "        return x.squeeze(1)"
            ],
            "metadata": {
                "id": "_8n5jykvUI9e"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def summarize():\n",
                "  model = CustomCNN()\n",
                "  if torch.cuda.is_available():\n",
                "      model = model.cuda()\n",
                "\n",
                "  # Summarize the model\n",
                "  summary(model, input_size=(3, *image_size))\n",
                "\n",
                "# summarize()"
            ],
            "metadata": {
                "id": "hysG-yYNL48s"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Train the model:**"
            ],
            "metadata": {
                "id": "g7N5IRYF_f5k"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Define the training loop\n",
                "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
                "    if is_train:\n",
                "        assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
                "\n",
                "    # Get number of batches\n",
                "    num_batches = len(dataloader)\n",
                "\n",
                "    # Set model to train mode or evaluation mode\n",
                "    if is_train:\n",
                "        model.train()\n",
                "    else:\n",
                "        model.eval()\n",
                "\n",
                "    # Define variables to save predictions and labels during the epoch\n",
                "    total_loss = 0.0\n",
                "    preds = []\n",
                "    labels = []\n",
                "\n",
                "    # Enable/disable gradients based on whether the model is in train or evaluation mode\n",
                "    with torch.set_grad_enabled(is_train):\n",
                "\n",
                "        # Analyse all batches\n",
                "        for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
                "\n",
                "            # Put data in same device as model (GPU or CPU)\n",
                "            X, y = X.to(device), y.to(device)\n",
                "\n",
                "            # Forward pass to obtain prediction of the model\n",
                "            pred = model(X)\n",
                "\n",
                "            # Compute loss between prediction and ground-truth\n",
                "            loss = loss_fn(pred, y.float())  # Convert labels to float for regression task\n",
                "\n",
                "            # Backward pass\n",
                "            if is_train:\n",
                "                # Reset gradients in optimizer\n",
                "                optimizer.zero_grad()\n",
                "                # Calculate gradients by backpropagating loss\n",
                "                loss.backward()\n",
                "                # Update model weights based on the calculated gradients\n",
                "                optimizer.step()\n",
                "\n",
                "            # Save training metrics\n",
                "            total_loss += loss.item()  # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
                "\n",
                "            # Add predictions\n",
                "            preds.extend(pred.detach().cpu().numpy())\n",
                "            labels.extend(y.cpu().numpy())\n",
                "\n",
                "    return total_loss / num_batches, mean_absolute_error(labels, preds)"
            ],
            "metadata": {
                "id": "x2PFDAsJVHKR"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Driver code:**"
            ],
            "metadata": {
                "id": "jFP-obDiVN8a"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(device)\n",
                "train_history_file = f'{plot_data}train_history.json'\n",
                "val_history_file = f'{plot_data}val_history.json'\n",
                "latest_model_file = f'{models_folder}latest_model.pth'\n",
                "best_model_file = f'{models_folder}best_model.pth'\n",
                "print(\"Continue previous training or start new one?\")\n",
                "print(\"1: Continue\")\n",
                "print(\"2: Start new one\")\n",
                "choice = input()\n",
                "\n",
                "model = CustomCNN()\n",
                "criterion = nn.L1Loss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "num_epochs = 30\n",
                "epoch=0\n",
                "train_history = {'loss': [], 'accuracy': []}\n",
                "val_history = {'loss': [], 'accuracy': []}\n",
                "best_val_loss = float('inf')\n",
                "\n",
                "if choice == '1':\n",
                "  print(\"Resuming training...\")\n",
                "  checkpoint = torch.load(latest_model_file)\n",
                "  model.load_state_dict(checkpoint['model'])\n",
                "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
                "  model.to(device)\n",
                "  epoch = checkpoint['epoch']+1\n",
                "  train_history = get_saved_dict(train_history_file)\n",
                "  val_history = get_saved_dict(val_history_file)\n",
                "  best_val_loss = min(val_history['loss'])\n",
                "elif choice == '2':\n",
                "  print(\"New train\")\n",
                "  model.to(device)\n",
                "  if os.path.exists(train_history_file):\n",
                "    os.remove(train_history_file)\n",
                "  if os.path.exists(val_history_file):\n",
                "    os.remove(val_history_file)\n",
                "  if os.path.exists(latest_model_file):\n",
                "    os.remove(latest_model_file)\n",
                "\n"
            ],
            "metadata": {
                "id": "O3dCvI5D_xBq",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "status": "ok",
                    "timestamp": 1715852929791,
                    "user_tz": -60,
                    "elapsed": 3440,
                    "user": {
                        "displayName": "Andr\u00e9 Filipe Garcez Moreira de Sousa",
                        "userId": "09231004892304125355"
                    }
                },
                "outputId": "91ef517c-7c17-488d-d89d-826e0be39f78"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"Start training...\")\n",
                "for t in range(epoch, num_epochs):\n",
                "    print(f\"\\nEpoch {t}\")\n",
                "\n",
                "    # Train model for one iteration on training data\n",
                "    train_loss, train_acc = epoch_iter(train_dataloader, model, criterion, optimizer)\n",
                "    print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
                "\n",
                "    # Evaluate model on validation data\n",
                "    val_loss, val_acc = epoch_iter(valid_dataloader, model, criterion, None, is_train=False)\n",
                "    print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
                "\n",
                "    # Save model when validation loss improves\n",
                "    if val_loss < best_val_loss:\n",
                "        best_val_loss = val_loss\n",
                "        save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
                "        torch.save(save_dict, best_model_file)\n",
                "\n",
                "    # Save latest model\n",
                "    save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
                "    torch.save(save_dict, latest_model_file)\n",
                "\n",
                "    # Save training history for plotting purposes\n",
                "    train_history[\"loss\"].append(train_loss)\n",
                "    train_history[\"accuracy\"].append(train_acc)\n",
                "\n",
                "    val_history[\"loss\"].append(val_loss)\n",
                "    val_history[\"accuracy\"].append(val_acc)\n",
                "\n",
                "    save_dict_to_file(train_history, train_history_file)\n",
                "    save_dict_to_file(val_history, val_history_file)\n",
                "\n",
                "    plotTrainingHistory(train_history, val_history)\n",
                "\n",
                "print(\"Finished\")"
            ],
            "metadata": {
                "id": "MjyiyfX_VMIc",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "outputId": "8078770e-7b14-41dc-98ea-254f96c62678"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Test the model"
            ],
            "metadata": {
                "id": "bDiC7bYxZTy9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "model = CustomCNN().to(device)\n",
                "checkpoint = torch.load(best_model_file)\n",
                "model.load_state_dict(checkpoint['model'])\n",
                "\n",
                "test_loss, test_acc = epoch_iter(test_dataloader, model, criterion, is_train=False)\n",
                "print(f'\\nTest Loss: {test_loss:.3f} \\nTest Accuracy: {test_acc:.3f}')"
            ],
            "metadata": {
                "id": "S0GElrG2ZVBm"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}